{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3835a13-8816-4c18-ac95-214fca6ab70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponential LR directories: []\n",
      "Linear LR directories: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No valid data found in any of the provided log directories.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merged_df\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# --- Aggregate Data for Both Conditions ---\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m df_exp_agg \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_lr_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrollout/ep_rew_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m df_ln_agg  \u001b[38;5;241m=\u001b[39m aggregate_runs(ln_lr_dirs, tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrollout/ep_rew_mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# --- Set Professional Plot Style ---\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36maggregate_runs\u001b[0;34m(log_dirs, tag)\u001b[0m\n\u001b[1;32m     41\u001b[0m         dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid data found in any of the provided log directories.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m: dfs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dfs):\n",
      "\u001b[0;31mValueError\u001b[0m: No valid data found in any of the provided log directories."
     ]
    }
   ],
   "source": [
    "# Note: ChatGPT assisted in generating the following cell code for visualization.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "# --- Helper Function to Load TensorBoard Data ---\n",
    "def load_tensorboard_df(log_dir, tag='rollout/ep_rew_mean'):\n",
    "    ea = event_accumulator.EventAccumulator(log_dir, size_guidance={'scalars': 0})\n",
    "    ea.Reload()\n",
    "    events = ea.Scalars(tag)\n",
    "    if not events:\n",
    "        print(f\"No events found for tag '{tag}' in {log_dir}\")\n",
    "    df = pd.DataFrame(\n",
    "        [(e.wall_time, e.step, e.value) for e in events],\n",
    "        columns=['wall_time', 'step', 'value']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# --- Define Base Directories ---\n",
    "base_log_dir = '/mnt/c/Users/SHiFT/OneDrive/Documents/dev/Kane vs Abel Mortal Kombat II/experiments/logs/DuelingDDQN'\n",
    "exp_lr_base = os.path.join(base_log_dir, 'DuelingDoubleDQN_4M_VeryEasyVsJax_ExpLr')\n",
    "ln_lr_base  = os.path.join(base_log_dir, 'DuelingDoubleDQN_4M_VeryEasyVsJax_LnLr')\n",
    "\n",
    "# --- Create List of Log Directories for Each Condition ---\n",
    "exp_lr_dirs = [os.path.join(exp_lr_base, d) for d in os.listdir(exp_lr_base) \n",
    "               if os.path.isdir(os.path.join(exp_lr_base, d))]\n",
    "ln_lr_dirs  = [os.path.join(ln_lr_base, d) for d in os.listdir(ln_lr_base) \n",
    "               if os.path.isdir(os.path.join(ln_lr_base, d))]\n",
    "\n",
    "print(\"Exponential LR directories:\", exp_lr_dirs)\n",
    "print(\"Linear LR directories:\", ln_lr_dirs)\n",
    "\n",
    "def aggregate_runs(log_dirs, tag='rollout/ep_rew_mean'):\n",
    "    dfs = []\n",
    "    for log_dir in log_dirs:\n",
    "        df = load_tensorboard_df(log_dir, tag=tag)\n",
    "        print(f\"Loaded {len(df)} events from {log_dir}\")\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "    if not dfs:\n",
    "        raise ValueError(\"No valid data found in any of the provided log directories.\")\n",
    "    merged_df = pd.DataFrame({'step': dfs[0]['step']})\n",
    "    for i, df in enumerate(dfs):\n",
    "        merged_df[f'value_run{i}'] = df['value'].values\n",
    "    value_columns = [col for col in merged_df.columns if col.startswith('value_run')]\n",
    "    merged_df['mean'] = merged_df[value_columns].mean(axis=1)\n",
    "    merged_df['std'] = merged_df[value_columns].std(axis=1, ddof=1)\n",
    "    return merged_df\n",
    "\n",
    "# --- Aggregate Data for Both Conditions ---\n",
    "df_exp_agg = aggregate_runs(exp_lr_dirs, tag='rollout/ep_rew_mean')\n",
    "df_ln_agg  = aggregate_runs(ln_lr_dirs, tag='rollout/ep_rew_mean')\n",
    "\n",
    "# --- Set Professional Plot Style ---\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'lines.linewidth': 1.0,\n",
    "    'lines.markersize': 4,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 300,\n",
    "})\n",
    "\n",
    "# --- Plot Only the Standard Deviation (Std) Curves ---\n",
    "plt.figure(figsize=(12, 6), dpi=300)\n",
    "\n",
    "# Color choices (colorblind-friendly)\n",
    "exp_color = '#0072B2'\n",
    "ln_color  = '#D55E00'\n",
    "\n",
    "plt.plot(\n",
    "    df_exp_agg['step'], df_exp_agg['std'],\n",
    "    label='Exponential LR Std',\n",
    "    color=exp_color,\n",
    "    linestyle='--'\n",
    ")\n",
    "plt.plot(\n",
    "    df_ln_agg['step'], df_ln_agg['std'],\n",
    "    label='Linear LR Std',\n",
    "    color=ln_color,\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Standard Deviation of Episode Reward Mean')\n",
    "plt.title('Standard Deviation Comparison: Exponential vs. Linear LR\\n(Liu Kang vs. Jax, Very Easy CPU Opponent)')\n",
    "plt.legend(loc='upper left', frameon=True)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('std_comparison.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl-env)",
   "language": "python",
   "name": "rl-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
