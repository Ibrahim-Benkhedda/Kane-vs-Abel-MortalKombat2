import numpy as np

from typing import Dict, Any, Optional
from mk_ai.agents import Agent

class DQNAgent(Agent):
    """Wrapper for Stable Baselines3 models with frame stacking."""
    
    def __init__(self, model, frame_stack: int = 4) -> None:
        """
        Initialize a DQNAgent.

        Parameters:
            - model: The pre-trained model to use for action selection.
            - frame_stack (int): Number of frames to stack for observation.
        """
        self.model = model
        self.frame_stack = frame_stack

        # Buffer for storing stacked observations
        self._obs_buffer: Optional[np.ndarray] = None

    def _update_obs_buffer(self, obs: np.ndarray) -> None:
        """
        Maintain observation history for frame stacking.

        Parameters:
            - obs (np.ndarray): The current observation from the environment.

        NOTE: this method has been generated by LLM. 
        """
        if self._obs_buffer is None:
            self._obs_buffer = np.repeat(obs, self.frame_stack, axis=-1)
        else:
            self._obs_buffer = np.concatenate(
                [self._obs_buffer[..., 1:], obs], axis=-1
            )

    def select_action(self, obs: np.ndarray, info: Dict[str, Any]) -> int:
        """
        Select an action based on the stacked observations.

        Parameters:
            - obs (np.ndarray): The current observation from the environment.
            - info (Dict[str, Any]): Additional information from the environment.

        Returns:
            - int: The selected action.
        """
        self._update_obs_buffer(obs)
        action, _ = self.model.predict(self._obs_buffer, deterministic=True)
        return int(action)